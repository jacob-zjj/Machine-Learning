本章内容：
	使用概率分布进行分类
	学习朴素贝叶斯分类器
	解析RSS源数据
	使用朴素贝叶斯来分析不同地区的态度
首先从一个简单的概率分类器开始，然后给出一些假设来学习朴素贝叶斯分类器。

基于贝叶斯决策理论的分类方法：
	优点：在数据缺少的情况下任然有效，可以处理很多分类别问题。
	缺点：对于输入数据的准备方式较为敏感。
	适用数据类型：标称型数据。

贝叶斯决策理论：
	p1(x,y)表示数据点(x,y)属于类别1(图中用圆点表示的类别)的概率
	p2(x,y)表示数据点(x,y)属于类别2(图中三角形表示的类别)的概率
	如果p1(x,y) > p2(x,y),那么类别1
	如果p2(x,y) > p1(x,y),那么类别2
真正需要比较的是p(c1|x,y)和p(c2|x,y)。这些符号的具体意义是：给定某个由x,y表示的数据点，那么数据点来自类别c1的概率是多少？数据点来自类别c2的概率又是多少？
	如果p(c1|x,y) > p(c2|x,y)，那么属于类别c1
	如果p(c1|x,y) < p(c2|x,y)，那么属于类别c2

使用朴素贝叶斯进行文档分类：
	朴素贝叶斯的一般过程：
	(1)收集数据：可以使用任何方法。文章使用RSS数据
	(2)准备数据：需要数值型或者布尔型数据。
	(3)分析数据：有大量特征时，绘制特征作用不大，此时使用直方图效果更好
	(4)训练算法：计算不用的独立特征的条件概率
	(5)测试算法：计算错误率
	(6)使用算法：一个常见的朴素贝叶斯应用是文档分类。可以在任意的分类场景中使用朴素贝叶斯分类器，不一定非要是文本。

计算每个类别中的文档数目：
对每篇训练文档：
	对每个类别：
		如果词条出现在文档中 -> 增加该词条的计数值
		增加所有词条的计数值
	对每个类别：
		对每个词条：
			将该词条的数目除以总词条数目得到条件概率
	返回每个类别的条件概率。

预测算法：
	利用贝叶斯对文档进行分类时，要计算多个概率的乘积以获得文档属于某个类别的概率，即计算配p(w0|1)p(w1|1)p(w2|1)。如果其中一个概率值为0，那么最后的乘积也为0，为降低这种影响，可以将所有词出现数初始化为1，并将分母初始化为2；

准备数据：文档词袋模型
	目前为止，我们将每个词的出现与否作为一个特征，这可以被描述为词集模型。如果一个词在文档中出现不止一次，这可能以为着包含该词是否出现在文档中所有不能表达的信息，这种方法被称为词袋模型，在词袋中，每个单词可以出现多次，而在词集中每个词只能出现一次。

示例：使用朴素贝叶斯过滤垃圾邮件
	（1）收集数据：提供文本文件
	（2）准备数据：将文本文件解析成词条向量
	（3）分析数据：检查词条确保解析的正确性
	（4）训练算法：使用我们之前建立的trainNB0()函数
	（5）测试算法：使用classifyNB(),并且构建一个新的测试函数来计算文档集的错误率
	（6）使用算法：构建一个完整的程序对一组文档进行分类，将错分的文档输出到屏幕上

留存交叉验证法：
	随机选择数据中的一部分作为训练集，而剩余部分作为测试集的过程称为留存交叉验证


示例：使用朴素贝叶斯分类器从个人广告中获取区域倾向：
	示例：使用朴素贝叶斯来发现地域相关的用词
	（1）收集数据：从RSS源收集内容，这里需要对RSS源构建一个接口
	（2）准备数据：将文本文件解析成词条向量
	（3）分析数据：检查词条确保解析的正确性
	（4）训练算法：使用我们之前建立的trainNBO()函数。
	（5）测试算法：观察错误率，确保分类器即可。可以修改切分程序，以降低错误率，提高分类结果
	（6）使用算法：构建一个完整的程序，封装所有内容。给定两个RSS源，该程序会显示最常用的公共词
	