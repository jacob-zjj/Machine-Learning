本章内容：
	降维技术
	主成分分析(PCA)
	对半导体数据进行降维处理
对数据进行简化还有下列一系列原因：
	（1）使得数据集更易使用
	（2）降低很多算法的计算开销
	（3）去除噪声
	（4）使得结果易懂
第一种降维的方法称为主成分分析（PCA）。在PCA中，数据从原来的坐标系转换到了新的坐标系，新坐标系的选择是由数据本身决定的。第一个新坐标轴选择的是原始数据中方差最大的方向，第二个新坐标轴的选择和第一个坐标轴正交且具有最大方差的方向，该过程一直重复，重复次数为原始数据中特征的数目。我们会发现，大部分方差都包含在最前面的几个新坐标轴中。因此我们可以忽略余下的坐标轴。

另外一种降维技术是因子分析。在因子分析中，我们假设在观察数据的生成中有一些观察不到的隐变量。假设观察数据是这些隐变量和某些噪声的线性组合。那么隐变量的数据可能比观察数据的数目少，也就是说通过找到隐变量就可以实现数据的降维。因子分析已经应用于社会科学、金融和其他领域了。

另外一种降维技术是独立成分分析（ICA）。ICA假设数据是从N个数据源生成的，这一点和因子分析有些类似。假设数据为多个数据源的混合观察结果，这些数据源之间在统计上是相互独立的，而在PCA中只假设数据是不相关的。同因子分析一样，如果数据源的数目少于观察数据的数目，则可以实现降维过程。

PCA

	主成分分析
	优点：降低数据的复杂性，识别最重要的多个特征
	缺点：不一定需要，且可能损失有用信息
	适用数据类型：数值型数据

特征值分析：
	特征值分析是线性代数中的一个领域，它能够通过数据的一般格式来揭示数据的“真实”结构，即我们常说的特征向量和特征值。在等式AV = λV中，V是特征向量，λ是特征值。特征值都是简单的标量值，因此AV = λV代表的是：如果特征向量V被某个矩阵A左乘，那么它就等于某个标量λ乘以V，幸运的是，numpy中有寻找特征值和特征向量的模块linalg，它有eig方法，该方法用于求解特征向量和特征值。

13.2.2在Numpy中实现PCA

13.3示例：利用PCA对半导体制造数据降维


